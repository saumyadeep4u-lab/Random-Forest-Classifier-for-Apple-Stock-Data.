# Random-Forest-Classifier-for-Apple-Stock-Data.
This project develops a robust Machine Learning pipeline to predict stock price movement using historical Apple stock data. A Random Forest Classifier is implemented with cross-validation and GridSearch optimization to achieve high predictive performance, evaluated using accuracy, precision, recall, F1-score, and ROC‚ÄìAUC metrics.
üìÇ Dataset

File: apple_stocks.csv

Contains historical stock information such as:

Date

Open

High

Low

Close

Volume

üöÄ Project Workflow (Step-by-Step)

1Ô∏è‚É£ Import Libraries

Essential Python libraries were imported for:

Data handling ‚Üí pandas, numpy

Visualization ‚Üí matplotlib, seaborn

Machine Learning ‚Üí sklearn

2Ô∏è‚É£ Data Loading

Dataset loaded into a Pandas DataFrame.

Initial inspection performed using:

.head()

.info()

.describe()

3Ô∏è‚É£ Data Preprocessing

The following cleaning steps were applied:

Removed duplicate records

Converted Date column to datetime format

Checked and handled missing values

Converted date into separate features:

Year

Month

Day

Removed original date index for modeling

4Ô∏è‚É£ Exploratory Data Analysis (EDA)

Visualizations were created to understand trends and distributions:

Stock price trends over time

Trading volume patterns

Comparison of Open, High, Low, Close prices

Distribution plots

Daily returns analysis

EDA helped identify patterns, volatility, and feature relationships.

5Ô∏è‚É£ Feature Engineering

New features were created to improve model performance:

Daily Returns

Price Change

High‚ÄìLow Range

Moving Average (MA)

Lag Features (previous closing prices)

6Ô∏è‚É£ Define Features and Target

Features (X): Engineered numerical variables

Target (y): Price movement category (classification)

7Ô∏è‚É£ Train‚ÄìTest Split

Dataset split into:

Training Set

Testing Set

Typically using:

train_test_split(test_size=0.2, random_state=42)
8Ô∏è‚É£ Model Selection

A Random Forest Classifier was used because:

Handles nonlinear relationships well

Robust to noise

Works effectively on tabular financial data

9Ô∏è‚É£ Hyperparameter Tuning

Hyperparameters were optimized using GridSearchCV with K-Fold Cross Validation.

Example parameters tuned:

n_estimators

max_depth

min_samples_split

min_samples_leaf

criterion

This step finds the best combination for optimal performance.

üîü K-Fold Cross Validation

K-Fold validation was applied to:

Reduce overfitting risk

Ensure model stability

Evaluate performance consistency across folds

1Ô∏è‚É£1Ô∏è‚É£ Model Training

The final model was trained using the best hyperparameters obtained from Grid Search.

1Ô∏è‚É£2Ô∏è‚É£ Model Evaluation

Performance evaluated on the test set using:

Accuracy

Precision

Recall

F1 Score

Classification Report

1Ô∏è‚É£3Ô∏è‚É£ ROC Curve and AUC Score

Receiver Operating Characteristic (ROC) curve used to measure classification quality.

AUC close to 1.0 indicates excellent model performance.

Shows strong ability to distinguish between classes.

üìä Results

High test accuracy achieved

Strong ROC‚ÄìAUC performance

Balanced precision and recall

üõ†Ô∏è Technologies Used

Python

Pandas

NumPy

Matplotlib / Seaborn

Scikit-learn

Jupyter Notebook
